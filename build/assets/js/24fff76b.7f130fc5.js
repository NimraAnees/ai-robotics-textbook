"use strict";(globalThis.webpackChunkai_robotics_textbook=globalThis.webpackChunkai_robotics_textbook||[]).push([[4112],{8173:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"module-3-ai-robot-brain/chapter-5","title":"Chapter 5: Isaac Sim and Synthetic Data Generation","description":"Overview","source":"@site/docs/module-3-ai-robot-brain/chapter-5.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/chapter-5","permalink":"/ai-robotics-textbook/docs/module-3-ai-robot-brain/chapter-5","draft":false,"unlisted":false,"editUrl":"https://github.com/humonide-book/ai-robotics-textbook/edit/main/docs/module-3-ai-robot-brain/chapter-5.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Chapter 5: Isaac Sim and Synthetic Data Generation","sidebar_position":1},"sidebar":"textbookSidebar","previous":{"title":"Learning Objectives","permalink":"/ai-robotics-textbook/docs/module-3-ai-robot-brain/learning-objectives"},"next":{"title":"Chapter 6: Isaac ROS (VSLAM, Navigation, Perception)","permalink":"/ai-robotics-textbook/docs/module-3-ai-robot-brain/chapter-6"}}');var t=i(4848),s=i(8453);const r={sidebar_label:"Chapter 5: Isaac Sim and Synthetic Data Generation",sidebar_position:1},o="Chapter 5: Isaac Sim and Synthetic Data Generation",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"5.1 Introduction to NVIDIA Isaac Sim",id:"51-introduction-to-nvidia-isaac-sim",level:2},{value:"What is Isaac Sim?",id:"what-is-isaac-sim",level:3},{value:"Key Features",id:"key-features",level:3},{value:"5.2 Installing and Setting Up Isaac Sim",id:"52-installing-and-setting-up-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Process",id:"installation-process",level:3},{value:"Docker Installation Example",id:"docker-installation-example",level:3},{value:"5.3 Synthetic Data Generation Pipeline",id:"53-synthetic-data-generation-pipeline",level:2},{value:"Why Synthetic Data?",id:"why-synthetic-data",level:3},{value:"Data Generation Components",id:"data-generation-components",level:3},{value:"Example Python API Usage",id:"example-python-api-usage",level:3},{value:"5.4 Domain Randomization Techniques",id:"54-domain-randomization-techniques",level:2},{value:"Concept of Domain Randomization",id:"concept-of-domain-randomization",level:3},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physical Domain Randomization",id:"physical-domain-randomization",level:3},{value:"Example Domain Randomization",id:"example-domain-randomization",level:3},{value:"5.5 Isaac Sim Sensors and Data Generation",id:"55-isaac-sim-sensors-and-data-generation",level:2},{value:"Supported Sensors",id:"supported-sensors",level:3},{value:"Sensor Configuration Example",id:"sensor-configuration-example",level:3},{value:"5.6 Synthetic Dataset Creation",id:"56-synthetic-dataset-creation",level:2},{value:"Dataset Structure",id:"dataset-structure",level:3},{value:"Data Pipeline Example",id:"data-pipeline-example",level:3},{value:"5.7 Quality Validation",id:"57-quality-validation",level:2},{value:"Data Quality Metrics",id:"data-quality-metrics",level:3},{value:"Validation Techniques",id:"validation-techniques",level:3},{value:"5.8 Practical Exercise: Synthetic Data Pipeline",id:"58-practical-exercise-synthetic-data-pipeline",level:2},{value:"Exercise Objective",id:"exercise-objective",level:3},{value:"Steps",id:"steps",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Summary",id:"summary",level:2},{value:"Key Terms",id:"key-terms",level:2},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chapter-5-isaac-sim-and-synthetic-data-generation",children:"Chapter 5: Isaac Sim and Synthetic Data Generation"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"This chapter introduces NVIDIA Isaac Sim, a photorealistic simulation environment for robotics development. Students will learn to set up Isaac Sim, configure synthetic data generation pipelines, and create realistic training datasets for AI models. Isaac Sim enables the generation of diverse, labeled data that would be expensive or impossible to collect in the real world."}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set up and configure NVIDIA Isaac Sim for humanoid robotics"}),"\n",(0,t.jsx)(n.li,{children:"Implement synthetic data generation pipelines"}),"\n",(0,t.jsx)(n.li,{children:"Create diverse training datasets with realistic variations"}),"\n",(0,t.jsx)(n.li,{children:"Configure domain randomization techniques"}),"\n",(0,t.jsx)(n.li,{children:"Validate synthetic data quality for real-world applications"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"51-introduction-to-nvidia-isaac-sim",children:"5.1 Introduction to NVIDIA Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"what-is-isaac-sim",children:"What is Isaac Sim?"}),"\n",(0,t.jsx)(n.p,{children:"NVIDIA Isaac Sim is a reference application built on NVIDIA Omniverse for simulating autonomous robots. It provides:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Photorealistic rendering for synthetic data generation"}),"\n",(0,t.jsx)(n.li,{children:"Accurate physics simulation"}),"\n",(0,t.jsx)(n.li,{children:"ROS2 and ROS1 bridge support"}),"\n",(0,t.jsx)(n.li,{children:"Flexible sensor simulation"}),"\n",(0,t.jsx)(n.li,{children:"AI training environments"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Photorealistic Rendering"}),": Based on NVIDIA Omniverse platform"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Physics Accuracy"}),": Supports PhysX and Flex physics engines"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Simulation"}),": LiDAR, cameras, IMUs, force/torque sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS Bridge"}),": Native ROS2 support with message translation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI Training"}),": Built-in reinforcement learning environments"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"52-installing-and-setting-up-isaac-sim",children:"5.2 Installing and Setting Up Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"NVIDIA GPU with RTX or GTX 1080/2080/3080/4080 series"}),"\n",(0,t.jsx)(n.li,{children:"CUDA 11.8 or later"}),"\n",(0,t.jsx)(n.li,{children:"Ubuntu 20.04 or 22.04 (recommended)"}),"\n",(0,t.jsx)(n.li,{children:"At least 16GB RAM (32GB recommended)"}),"\n",(0,t.jsx)(n.li,{children:"50GB+ free disk space"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"installation-process",children:"Installation Process"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install NVIDIA drivers and CUDA toolkit"}),"\n",(0,t.jsx)(n.li,{children:"Install Isaac Sim via pip or Docker"}),"\n",(0,t.jsx)(n.li,{children:"Configure GPU access and permissions"}),"\n",(0,t.jsx)(n.li,{children:"Verify installation with basic simulation"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"docker-installation-example",children:"Docker Installation Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Pull Isaac Sim Docker image\ndocker pull nvcr.io/nvidia/isaac-sim:4.0.0\n\n# Run Isaac Sim with GPU access\ndocker run --gpus all -it --rm \\\n  --network=host \\\n  --env "ACCEPT_EULA=Y" \\\n  --env "LOCAL_UID=$(id -u)" \\\n  --env "LOCAL_GID=$(id -g)" \\\n  --volume "$(pwd):/workspace" \\\n  --volume "/tmp/.X11-unix:/tmp/.X11-unix:rw" \\\n  --env "DISPLAY=$DISPLAY" \\\n  --device "/dev/dxgi" \\\n  --device "/dev/nvidia0" \\\n  nvcr.io/nvidia/isaac-sim:4.0.0\n'})}),"\n",(0,t.jsx)(n.h2,{id:"53-synthetic-data-generation-pipeline",children:"5.3 Synthetic Data Generation Pipeline"}),"\n",(0,t.jsx)(n.h3,{id:"why-synthetic-data",children:"Why Synthetic Data?"}),"\n",(0,t.jsx)(n.p,{children:"Synthetic data generation addresses key challenges in robotics AI:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cost"}),": Real data collection is expensive and time-consuming"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safety"}),": Dangerous scenarios can be safely simulated"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Variety"}),": Unlimited environmental variations possible"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Annotation"}),": Perfect ground truth for training data"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Repeatability"}),": Identical scenarios can be reproduced"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"data-generation-components",children:"Data Generation Components"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scene Generation"}),": Creating diverse environments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Object Placement"}),": Randomizing object positions and properties"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lighting Variation"}),": Simulating different lighting conditions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Simulation"}),": Generating realistic sensor outputs"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Annotation Pipeline"}),": Creating ground truth labels"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"example-python-api-usage",children:"Example Python API Usage"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\n\n# Initialize Isaac Sim\nworld = World(stage_units_in_meters=1.0)\n\n# Load robot model\nadd_reference_to_stage(\n    usd_path="/path/to/humanoid_robot.usd",\n    prim_path="/World/Humanoid"\n)\n\n# Configure synthetic data helper\nsynthetic_data_helper = SyntheticDataHelper(\n    viewport_name="Viewport",\n    resolution=(640, 480)\n)\n\n# Generate synthetic RGB and depth data\nrgb_data = synthetic_data_helper.get_rgb()\ndepth_data = synthetic_data_helper.get_depth()\n\n# Process and save data\nimport cv2\ncv2.imwrite("synthetic_rgb.png", rgb_data)\ncv2.imwrite("synthetic_depth.png", depth_data)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"54-domain-randomization-techniques",children:"5.4 Domain Randomization Techniques"}),"\n",(0,t.jsx)(n.h3,{id:"concept-of-domain-randomization",children:"Concept of Domain Randomization"}),"\n",(0,t.jsx)(n.p,{children:"Domain randomization varies environmental parameters to make AI models robust across different conditions:"}),"\n",(0,t.jsx)(n.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lighting"}),": Randomize position, intensity, and color"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Materials"}),": Vary surface properties and textures"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Camera Properties"}),": Adjust focal length, distortion, noise"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Weather Effects"}),": Simulate rain, fog, snow conditions"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"physical-domain-randomization",children:"Physical Domain Randomization"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Friction"}),": Vary surface friction coefficients"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mass"}),": Add random variations to object masses"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dynamics"}),": Randomize joint damping and stiffness"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gravity"}),": Slight variations in gravitational force"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"example-domain-randomization",children:"Example Domain Randomization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.core.utils.stage import get_stage\n\ndef apply_domain_randomization():\n    stage = get_stage()\n\n    # Randomize lighting\n    light_prim = get_prim_at_path("/World/Light")\n    intensity = np.random.uniform(500, 1500)\n    light_prim.GetAttribute("inputs:intensity").Set(intensity)\n\n    # Randomize material properties\n    material_prim = get_prim_at_path("/World/Materials/RandomMaterial")\n    roughness = np.random.uniform(0.1, 0.9)\n    material_prim.GetAttribute("inputs:roughness").Set(roughness)\n\n    # Randomize object properties\n    object_prim = get_prim_at_path("/World/Object")\n    mass = np.random.uniform(0.8, 1.2) * base_mass\n    # Apply mass variation to object\n'})}),"\n",(0,t.jsx)(n.h2,{id:"55-isaac-sim-sensors-and-data-generation",children:"5.5 Isaac Sim Sensors and Data Generation"}),"\n",(0,t.jsx)(n.h3,{id:"supported-sensors",children:"Supported Sensors"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RGB Cameras"}),": High-fidelity color image generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Depth Cameras"}),": Accurate depth measurement"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LiDAR"}),": 3D point cloud generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"IMU"}),": Inertial measurement data"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Force/Torque Sensors"}),": Contact force measurement"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Stereo Cameras"}),": Depth from stereo vision"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"sensor-configuration-example",children:"Sensor Configuration Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import IMUSensor\nfrom omni.isaac.range_sensor import _RangeSensor\n\n# Create IMU sensor\nimu_sensor = IMUSensor(\n    prim_path="/World/Humanoid/base_link/Imu_Sensor",\n    name="humanoid_imu",\n    frequency=100,\n    sensor_period=0.0  # Immediate update\n)\n\n# Create LiDAR sensor\nlidar_sensor = _RangeSensor.acquire_lidar_sensor_interface()\nlidar_sensor.create_lidar(\n    prim_path="/World/Humanoid/base_link/Lidar_Sensor",\n    translation=np.array([0, 0, 0.5]),\n    orientation=np.array([1, 0, 0, 0]),\n    config="Custom",\n    params={\n        "min_range": 0.1,\n        "max_range": 25.0,\n        "ray_cnt_x": 640,\n        "ray_cnt_y": 1,\n        "horizontal_fov": 360\n    }\n)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"56-synthetic-dataset-creation",children:"5.6 Synthetic Dataset Creation"}),"\n",(0,t.jsx)(n.h3,{id:"dataset-structure",children:"Dataset Structure"}),"\n",(0,t.jsx)(n.p,{children:"A typical synthetic dataset includes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RGB Images"}),": Color images for visual recognition"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Depth Maps"}),": Per-pixel depth information"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Semantic Segmentation"}),": Pixel-level object classification"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Instance Segmentation"}),": Individual object identification"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bounding Boxes"}),": Object localization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ground Truth"}),": Accurate measurements and positions"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"data-pipeline-example",children:"Data Pipeline Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import os\nimport json\nimport numpy as np\nfrom PIL import Image\n\nclass SyntheticDatasetGenerator:\n    def __init__(self, output_dir):\n        self.output_dir = output_dir\n        self.data_index = 0\n\n        # Create output directories\n        os.makedirs(f"{output_dir}/rgb", exist_ok=True)\n        os.makedirs(f"{output_dir}/depth", exist_ok=True)\n        os.makedirs(f"{output_dir}/seg", exist_ok=True)\n        os.makedirs(f"{output_dir}/labels", exist_ok=True)\n\n    def generate_sample(self, rgb_data, depth_data, seg_data, ground_truth):\n        # Save RGB image\n        rgb_img = Image.fromarray(rgb_data)\n        rgb_img.save(f"{self.output_dir}/rgb/{self.data_index:06d}.png")\n\n        # Save depth map\n        depth_img = Image.fromarray(depth_data)\n        depth_img.save(f"{self.output_dir}/depth/{self.data_index:06d}.png")\n\n        # Save segmentation\n        seg_img = Image.fromarray(seg_data)\n        seg_img.save(f"{self.output_dir}/seg/{self.data_index:06d}.png")\n\n        # Save ground truth labels\n        with open(f"{self.output_dir}/labels/{self.data_index:06d}.json", \'w\') as f:\n            json.dump(ground_truth, f)\n\n        self.data_index += 1\n\n    def generate_dataset(self, num_samples):\n        for i in range(num_samples):\n            # Apply domain randomization\n            self.apply_scene_randomization()\n\n            # Render and collect data\n            rgb, depth, seg = self.render_frame()\n            gt = self.get_ground_truth()\n\n            # Generate sample\n            self.generate_sample(rgb, depth, seg, gt)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"57-quality-validation",children:"5.7 Quality Validation"}),"\n",(0,t.jsx)(n.h3,{id:"data-quality-metrics",children:"Data Quality Metrics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Visual Quality"}),": Check for rendering artifacts"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Geometric Accuracy"}),": Validate depth and pose accuracy"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Temporal Consistency"}),": Ensure smooth motion sequences"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Label Accuracy"}),": Verify annotation correctness"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"validation-techniques",children:"Validation Techniques"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cross-Validation"}),": Compare synthetic and real data distributions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Downstream Task Performance"}),": Test on actual robotics tasks"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Statistical Analysis"}),": Compare synthetic vs. real data statistics"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"58-practical-exercise-synthetic-data-pipeline",children:"5.8 Practical Exercise: Synthetic Data Pipeline"}),"\n",(0,t.jsx)(n.h3,{id:"exercise-objective",children:"Exercise Objective"}),"\n",(0,t.jsx)(n.p,{children:"Create a synthetic data generation pipeline for humanoid robot perception."}),"\n",(0,t.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Set up Isaac Sim environment with humanoid robot"}),"\n",(0,t.jsx)(n.li,{children:"Configure domain randomization parameters"}),"\n",(0,t.jsx)(n.li,{children:"Implement RGB and depth data collection"}),"\n",(0,t.jsx)(n.li,{children:"Add semantic segmentation capabilities"}),"\n",(0,t.jsx)(n.li,{children:"Create dataset with 1000+ samples"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"expected-results",children:"Expected Results"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Functional synthetic data pipeline"}),"\n",(0,t.jsx)(n.li,{children:"Diverse dataset with domain randomization"}),"\n",(0,t.jsx)(n.li,{children:"Validated data quality metrics"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim provides a powerful platform for synthetic data generation in robotics. By leveraging photorealistic rendering and physics simulation, we can create diverse, labeled datasets that enable robust AI model training. Domain randomization techniques ensure that models trained on synthetic data can generalize to real-world conditions."}),"\n",(0,t.jsx)(n.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synthetic Data"}),": Computer-generated data that mimics real-world observations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Domain Randomization"}),": Technique to vary simulation parameters for robustness"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Photorealistic Rendering"}),": High-fidelity visual simulation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ground Truth"}),": Accurate reference data for training and validation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Omniverse"}),": NVIDIA's simulation and collaboration platform"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/isaacsim.html",children:"NVIDIA Isaac Sim Documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2008.01805",children:"Synthetic Data for Robotics"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization in Robotics"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var a=i(6540);const t={},s=a.createContext(t);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);